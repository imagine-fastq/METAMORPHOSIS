import cv2
import numpy as np
import os
import random
from moviepy.editor import VideoFileClip, AudioFileClip, ImageSequenceClip
from scipy.io.wavfile import write

# ==========================================
# ğŸ§¬ METAMORPHOSIS ENGINE v1.0
# Theme: IV - DEEP ABYSS (Biyo-Dijital DÃ¶nÃ¼ÅŸÃ¼m)
# Author: imagine-fastq
# ==========================================

def generate_abyss_audio(duration, fps=30):
    """
    Kafkaesk 'Derin UÃ§urum' ses sentezi.
    40Hz-60Hz arasÄ± dÃ¼ÅŸÃ¼k frekanslÄ± drone sesi ve rastgele 'Sonar' sinyalleri Ã¼retir.
    """
    sample_rate = 44100
    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)
    
    # 1. Katman: The Void (DÃ¼ÅŸÃ¼k FrekanslÄ± Drone - 40Hz)
    # Okyanus tabanÄ± hissi veren sinÃ¼s dalgasÄ±
    drone_base = 0.5 * np.sin(2 * np.pi * 40 * t)
    
    # 2. Katman: ModÃ¼lasyon (LFO - Low Frequency Oscillation)
    # Sesi dalgalandÄ±rÄ±r (Nefes alÄ±p verme gibi)
    lfo = 0.5 * (1 + np.sin(2 * np.pi * 0.2 * t))
    drone_modulated = drone_base * lfo

    # 3. Katman: Sonar Pingleri (Veri Sinyalleri)
    # Rastgele anlarda yÃ¼ksek frekanslÄ± "bip" sesleri
    sonar_layer = np.zeros_like(t)
    num_pings = int(duration / 2) # Her 2 saniyede bir ping ortalamasÄ±
    
    for _ in range(num_pings):
        ping_time = random.uniform(0, duration)
        idx = int(ping_time * sample_rate)
        if idx < len(t):
            # KÄ±sa bir yÃ¼ksek frekans sinyali (800Hz)
            ping_duration = 0.1
            ping_t = np.linspace(0, ping_duration, int(sample_rate * ping_duration))
            ping_wave = 0.3 * np.sin(2 * np.pi * 800 * ping_t) * np.exp(-5 * ping_t) # SÃ¶nÃ¼mlenen ses
            
            end_idx = min(idx + len(ping_wave), len(t))
            sonar_layer[idx:end_idx] += ping_wave[:end_idx-idx]

    # KarÄ±ÅŸtÄ±rma (Mix)
    audio_signal = drone_modulated + sonar_layer
    
    # Normalizasyon (Ses patlamasÄ±nÄ± Ã¶nle)
    audio_signal = audio_signal / np.max(np.abs(audio_signal))
    return audio_signal, sample_rate

def apply_genomic_glitch(frame, frame_count):
    """
    GÃ¶rÃ¼ntÃ¼ karesine biyolojik/dijital mutasyon uygular.
    """
    h, w, c = frame.shape
    
    # EFEKT 1: KÄ±rmÄ±zÄ± Kod (Red Shift)
    # GÃ¶rÃ¼ntÃ¼nÃ¼n kÄ±rmÄ±zÄ± kanalÄ±nÄ± kaydÄ±rarak "ayrÄ±ÅŸma" yaratÄ±r
    shift_amount = int(5 + 10 * np.sin(frame_count * 0.1))
    b, g, r = cv2.split(frame)
    r = np.roll(r, shift_amount, axis=1) # KÄ±rmÄ±zÄ± kanalÄ± yana kaydÄ±r
    mutated = cv2.merge([b, g, r])

    # EFEKT 2: The Void (EÅŸikleme)
    # Belirli aralÄ±klarla gÃ¶rÃ¼ntÃ¼yÃ¼ sadece Siyah-Beyaz iskelete indirger
    if frame_count % 60 < 15: # Her saniyenin ilk 15 karesi
        gray = cv2.cvtColor(mutated, cv2.COLOR_BGR2GRAY)
        _, thresholded = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)
        # Siyah beyazÄ± 3 kanala Ã§evirip kÄ±rmÄ±zÄ±yla karÄ±ÅŸtÄ±r
        thresholded_bgr = cv2.cvtColor(thresholded, cv2.COLOR_GRAY2BGR)
        mutated = cv2.addWeighted(mutated, 0.7, thresholded_bgr, 0.3, 0)

    # EFEKT 3: Dijital YaÄŸmur (Binary Rain Noise)
    # Rastgele pikselleri bozar
    noise_density = 0.02 # %2 oranÄ±nda gÃ¼rÃ¼ltÃ¼
    num_pixels = int(h * w * noise_density)
    for _ in range(num_pixels):
        y_coord = random.randint(0, h - 1)
        x_coord = random.randint(0, w - 1)
        mutated[y_coord, x_coord] = [0, 0, 255] # Saf KÄ±rmÄ±zÄ± Noktalar

    return mutated

def main():
    print("\nğŸ§¬ METAMORPHOSIS BAÅLATILIYOR...")
    print(">> Hedef: Biyo-Dijital Veri DÃ¶nÃ¼ÅŸÃ¼mÃ¼")
    print(">> Tema: Deep Abyss (Theme 4)\n")

    input_video_path = "input.MOV"
    output_video_path = "imagine_fastq_THEME_4_ABYSS.mp4"
    temp_audio_path = "temp_abyss_audio.wav"

    # 1. Dosya KontrolÃ¼
    if not os.path.exists(input_video_path):
        print(f"âš ï¸ HATA: '{input_video_path}' bulunamadÄ±!")
        print(">> LÃ¼tfen iÅŸlenecek videoyu 'input.MOV' adÄ±yla bu klasÃ¶re atÄ±n.")
        return

    # 2. Video Analizi
    cap = cv2.VideoCapture(input_video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps

    print(f"ğŸ“¼ Video Analiz Edildi: {duration:.2f} saniye, {width}x{height}, {fps} FPS")

    # 3. GÃ¶rsel Ä°ÅŸleme DÃ¶ngÃ¼sÃ¼
    processed_frames = []
    print("ğŸ”¬ GÃ¶rsel Mutasyon BaÅŸlÄ±yor...")
    
    frame_count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Mutasyon fonksiyonunu Ã§aÄŸÄ±r
        glitch_frame = apply_genomic_glitch(frame, frame_count)
        
        # OpenCV BGR formatÄ±ndan RGB formatÄ±na Ã§evir (MoviePy iÃ§in)
        frame_rgb = cv2.cvtColor(glitch_frame, cv2.COLOR_BGR2RGB)
        processed_frames.append(frame_rgb)
        
        frame_count += 1
        if frame_count % 30 == 0:
            print(f"   >> Ä°ÅŸleniyor: Kare {frame_count}/{total_frames}")

    cap.release()

    # 4. Ä°ÅŸitsel Sentez (Procedural Audio)
    print("ğŸ”Š Ä°ÅŸitsel Sentez BaÅŸlÄ±yor (Deep Abyss)...")
    audio_data, sample_rate = generate_abyss_audio(duration)
    
    # Sesi geÃ§ici olarak kaydet
    write(temp_audio_path, sample_rate, (audio_data * 32767).astype(np.int16))

    # 5. BirleÅŸtirme (Muxing)
    print("ğŸ¬ Render AlÄ±nÄ±yor...")
    clip = ImageSequenceClip(processed_frames, fps=fps)
    audio = AudioFileClip(temp_audio_path)
    
    final_clip = clip.set_audio(audio)
    final_clip.write_videofile(output_video_path, codec='libx264', audio_codec='aac')

    # 6. Temizlik
    if os.path.exists(temp_audio_path):
        os.remove(temp_audio_path)

    print(